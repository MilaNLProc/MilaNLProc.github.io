<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>large language models | MilaNLP Lab @ Bocconi University</title>
    <link>https://milanlproc.github.io/tags/large-language-models/</link>
      <atom:link href="https://milanlproc.github.io/tags/large-language-models/index.xml" rel="self" type="application/rss+xml" />
    <description>large language models</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© MilaNLP, 2026</copyright><lastBuildDate>Fri, 12 Dec 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>large language models</title>
      <link>https://milanlproc.github.io/tags/large-language-models/</link>
    </image>
    
    <item>
      <title>SALMON</title>
      <link>https://milanlproc.github.io/project/salmon/</link>
      <pubDate>Fri, 12 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/project/salmon/</guid>
      <description>&lt;p&gt;&lt;strong&gt;SALMON – Social Awareness for better Large Language Model Learning&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;Funded by: 
&lt;a href=&#34;https://tef.tech/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tech Europe Foundation (TEF)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Despite consuming massive amounts of textual data, current large language models (LLMs) still struggle with tasks that require social awareness, such as understanding moral values and making decisions in sensitive situations. As a result, models are ill-aligned with human values and lack actionable social knowledge (i.e., &amp;ldquo;reading the room&amp;rdquo;). This gap is critical, as LLMs are increasingly used in sensitive areas, such as intercultural business negotiations, educational applications, and mental health support, that require social awareness.&lt;/p&gt;
&lt;p&gt;However, it is impossible to learn true social awareness through passive consumption of text. Current training approaches do not explicitly address critical social elements or explicitly represent social awareness as an objective, but approximate its effects through post-hoc instruction fine-tuning. Continuing a text-only training paradigm and hoping that social awareness will somehow emerge limits performance, potentially harming users by catastrophically misreading situations. Instead, models need to acquire social awareness as an integral part of their pre-training to match the areas they are already expected to cover. To develop genuine social understanding&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance</title>
      <link>https://milanlproc.github.io/publication/2025-trojanstego/</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-trojanstego/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent</title>
      <link>https://milanlproc.github.io/publication/2025-principled-personas/</link>
      <pubDate>Sun, 09 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-principled-personas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>IssueBench: Millions of Realistic Prompts for Measuring Issue Bias in LLM Writing Assistance</title>
      <link>https://milanlproc.github.io/publication/2025-issuebench/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-issuebench/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter</title>
      <link>https://milanlproc.github.io/publication/2025-hateday/</link>
      <pubDate>Mon, 21 Jul 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-hateday/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Around the World in 24 Hours: Probing LLM Knowledge of Time and Place</title>
      <link>https://milanlproc.github.io/publication/2025-geotemp/</link>
      <pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-geotemp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scaling language model size yields diminishing returns for single-message political persuasion</title>
      <link>https://milanlproc.github.io/publication/2025-scaling-persuasion/</link>
      <pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-scaling-persuasion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Specializing Large Language Models to Simulate Survey Response Distributions for Global Populations</title>
      <link>https://milanlproc.github.io/publication/2025-llm-survey-simulation/</link>
      <pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2025-llm-survey-simulation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The PRISM Alignment Dataset: What Participatory, Representative and Individualised Human Feedback Reveals About the Subjective and Multicultural Alignment of Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2024-prism/</link>
      <pubDate>Tue, 03 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-prism/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts</title>
      <link>https://milanlproc.github.io/publication/2024-liswo/</link>
      <pubDate>Sat, 09 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-liswo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Countering Hateful and Offensive Speech Online - Open Challenges</title>
      <link>https://milanlproc.github.io/publication/2024-tutorial-countering-hate-speech/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-tutorial-countering-hate-speech/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2024-divine-llamas-emotion-bias/</link>
      <pubDate>Sun, 22 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-divine-llamas-emotion-bias/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2024-compromesso/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-compromesso/</guid>
      <description></description>
    </item>
    
    <item>
      <title>My Answer is C: First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models</title>
      <link>https://milanlproc.github.io/publication/2024-myanswerisc/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-myanswerisc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Political Compass or Spinning Arrow? Towards More Meaningful Evaluations for Values and Opinions in Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2024-politicalcompass/</link>
      <pubDate>Sun, 11 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-politicalcompass/</guid>
      <description></description>
    </item>
    
    <item>
      <title>XSTest: A Test Suite for Identifying Exaggerated Safety Behaviors in Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2024-xstest/</link>
      <pubDate>Tue, 16 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-xstest/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts</title>
      <link>https://milanlproc.github.io/publication/2024-difficulty-classification/</link>
      <pubDate>Thu, 16 May 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-difficulty-classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language Models that Follow Instructions</title>
      <link>https://milanlproc.github.io/publication/2024-safetyllamas/</link>
      <pubDate>Tue, 07 May 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-safetyllamas/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety </title>
      <link>https://milanlproc.github.io/publication/2024-safetyprompts/</link>
      <pubDate>Mon, 08 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-safetyprompts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution</title>
      <link>https://milanlproc.github.io/publication/2024-emotion-gender-stereotypes/</link>
      <pubDate>Thu, 28 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-emotion-gender-stereotypes/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Classist Tools: Social Class Correlates with Performance in NLP</title>
      <link>https://milanlproc.github.io/publication/2024-socialclass-experiments/</link>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2024-socialclass-experiments/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Empty Signifier Problem: Towards Clearer Paradigms for Operationalising &#39;Alignment&#39; in Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2023-alignmentparadigms/</link>
      <pubDate>Wed, 15 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2023-alignmentparadigms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SimpleSafetyTests: a Test Suite for Identifying Critical Safety Risks in Large Language Models</title>
      <link>https://milanlproc.github.io/publication/2023-simplesafetytests/</link>
      <pubDate>Tue, 14 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2023-simplesafetytests/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values</title>
      <link>https://milanlproc.github.io/publication/2023-human-feedback-learning-survey/</link>
      <pubDate>Wed, 11 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/publication/2023-human-feedback-learning-survey/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
