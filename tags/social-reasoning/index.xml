<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>social reasoning | MilaNLP Lab @ Bocconi University</title>
    <link>https://milanlproc.github.io/tags/social-reasoning/</link>
      <atom:link href="https://milanlproc.github.io/tags/social-reasoning/index.xml" rel="self" type="application/rss+xml" />
    <description>social reasoning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© MilaNLP, 2025</copyright><lastBuildDate>Fri, 12 Dec 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>social reasoning</title>
      <link>https://milanlproc.github.io/tags/social-reasoning/</link>
    </image>
    
    <item>
      <title>SALMON</title>
      <link>https://milanlproc.github.io/project/salmon/</link>
      <pubDate>Fri, 12 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://milanlproc.github.io/project/salmon/</guid>
      <description>&lt;p&gt;&lt;strong&gt;SALMON – Social Awareness for better Large Language Model Learning&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;Funded by: 
&lt;a href=&#34;https://tef.tech/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tech Europe Foundation (TEF)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Despite consuming massive amounts of textual data, current large language models (LLMs) still struggle with tasks that require social awareness, such as understanding moral values and making decisions in sensitive situations. As a result, models are ill-aligned with human values and lack actionable social knowledge (i.e., &amp;ldquo;reading the room&amp;rdquo;). This gap is critical, as LLMs are increasingly used in sensitive areas, such as intercultural business negotiations, educational applications, and mental health support, that require social awareness.&lt;/p&gt;
&lt;p&gt;However, it is impossible to learn true social awareness through passive consumption of text. Current training approaches do not explicitly address critical social elements or explicitly represent social awareness as an objective, but approximate its effects through post-hoc instruction fine-tuning. Continuing a text-only training paradigm and hoping that social awareness will somehow emerge limits performance, potentially harming users by catastrophically misreading situations. Instead, models need to acquire social awareness as an integral part of their pre-training to match the areas they are already expected to cover. To develop genuine social understanding&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
